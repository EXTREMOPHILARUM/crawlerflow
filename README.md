# Web Crawler Plust

A micro-framework built on [scrapy](https://scrapy.org/) to crawl the sites. 
It can use [MongoDB](https://www.mongodb.com/), [Elasticsearch](https://www.elastic.co/products/elasticsearch) 
and [Solr](http://lucene.apache.org/solr/) databases to cache the requests and also extract the data using parser configs 
and save them.


[![Build Status](https://travis-ci.org/invanatech/web-crawler-plus.svg?branch=master)](https://travis-ci.org/invanatech/web-crawler-plus) | 
[![codecov](https://codecov.io/gh/invanatech/web-crawler-plus/branch/master/graph/badge.svg)](https://codecov.io/gh/invanatech/web-crawler-plus) | 
[Documentation](docs/index.md)

## Install

```bash

pip install web-crawler-plus

```

Checkout the [documentation](docs/index.md) for more information.


